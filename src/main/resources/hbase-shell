create 'gm_gidlist','gm'

import org.apache.hadoop.hbase.filter.CompareFilter
import org.apache.hadoop.hbase.filter.SubstringComparator
scan 'gm_user_action', {FILTER => org.apache.hadoop.hbase.filter.RowFilter.new(CompareFilter::CompareOp.valueOf('EQUAL'),SubstringComparator.new("uK2C3FOk8KBxihwAChfIAg6161"))}

scan 'gm_user_action', { COLUMNS => 'ua:cl'}

import org.apache.hadoop.hbase.filter.QualifierFilter
import org.apache.hadoop.hbase.filter.CompareFilter
import org.apache.hadoop.hbase.filter.SubstringComparator
import org.apache.hadoop.hbase.filter.BinaryComparator
import org.apache.hadoop.hbase.util.Bytes
import org.apache.hadoop.hbase.filter.SingleColumnValueFilter

scan 'gm_gidlist', { FILTER => QualifierFilter.new(CompareFilter::CompareOp.valueOf('EQUAL'),SubstringComparator.new("w"))}
scan 'gm_gidlist', {FILTER => SingleColumnValueFilter.new(Bytes.toBytes("gm"),Bytes.toBytes("gt"),CompareFilter::CompareOp.valueOf("EQUAL"),BinaryComparator.new(Bytes.toBytes("w")))}


crontab -e
50 17 * * * sh /home/hadoop/gmrec.sh /home/hadoop/rec /gmrec >> /home/hadoop/gmrec.log 2>&1 &



#awk '{gsub(/\[|\]|\{|\}|\"/,"",$2);print $2}' cfrec | awk -F "," '{print $1,$NF}' OFS="\n" >> cfrec1

awk '{gsub(/\[|\]|\{|\}|\"/,"",$2);print $2}' cfrec | awk -F "," '{ for (i=1;i<=NF;i++) print $i }' >> cfrec1

awk -F ":" '{print $1}' cfrec1  | sort | uniq -c | sort -nr >> cfrec2

#awk -F ":" '{print substr($1, 3, length($1)-3)}' cfrec1  | sort | uniq -c | sort -nr >> cfrec2

#按标签推荐的结果分析，输入数据时tagcf的输出
awk '{gsub(/\[|\]|\{|\}|\"/,"",$2);print $2}' tagcf |awk -F "," '{ for (i=1;i<=NF;i++) print $i }' | awk -F ":" '{if ($2>1) print $1}' |sort | uniq -c | sort -nr >> taganalyze
#按tag和gid排序分析，输入数据时hasgid的输出
awk -F "," '{print $2,$3}' tagrank | sort | uniq -c | sort -nr >> tagsort

awk -F "," '{print $1}' cfinput | sort |uniq -c|sort -nr >> ana
awk '{if ($1==1) print $2}' ana |wc -l
awk '{if ($1>1 && $1<4) print $2}' ana | wc -l

#统计每个gid的推荐结果数量
cat sim | awk '{split($2,a,",");print $1,length(a)}' >> aa

#统计每个gid的推荐结果数量，并输出推荐结果多余20个的项目
cat sim | awk '{if (split($2,a,",")>20) print $1,length(a)}' >> aa

#awk分组求和，文件格式为Language,game,count
awk -F "," '{w[$1]+=$3}END{for (a in w) print a,w[a]}' gamerank.csv

#统计代码行数
find . -name "*.java"|xargs cat|grep -v ^$|wc -l

#sql-script(game对应tagids映射表):
SELECT b.game_identify,GROUP_CONCAT(b.id SEPARATOR ':'),GROUP_CONCAT(b.tagname SEPARATOR ':') FROM(SELECT m.game_identify,t.id,t.tagname FROM www_tag t,www_tag_minigame_map m WHERE m.tag_id = t.id AND t.language = 'en' AND m.game_identify !='' ORDER BY m.game_identify)b GROUP BY b.game_identify
#sql-script取所有语种的tag-gid映射表
SELECT b.game_identify,b.`language`,GROUP_CONCAT(b.id SEPARATOR ':'),GROUP_CONCAT(b.tagname SEPARATOR ':') FROM(SELECT m.game_identify,t.id,t.`language`,t.tagname FROM www_tag t,www_tag_minigame_map m WHERE m.tag_id = t.id  AND m.game_identify !='' ORDER BY m.game_identify)b GROUP BY b.game_identify,b.`language` INTO OUTFILE "D:\\tag.csv" FIELDS TERMINATED BY ',';

#hive-script
create table game_rank(language string,gid string,palys int)ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
insert overwrite table game_rank select substr(language,0,2),gid,count(1) from game_play_action group by substr(language,0,gid,2),gid;

#将hbase的gm_gidlist映射到hive
hive -hiveconf hbase.zookeeper.quorum=dmnode3,dmnode4,dmnode5
CREATE EXTERNAL TABLE gm_gidtagmap(id string,gt string,ar string,de string,en string,es string,fr string,ja string,nl string,pl string,pt string,th string,tr string,tw string,zh string) STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,gm:gt,gm:ar,gm:de,gm:en,gm:es,gm:fr,gm:ja,gm:nl,gm:pl,gm:pt,gm:th,gm:tr,gm:tw,gm:zh")  TBLPROPERTIES ("hbase.table.name" = "gm_gidlist");
CREATE EXTERNAL TABLE game_tag_map(id string,gt string,ar string,de string,en string,es string,fr string,ja string,nl string,pl string,pt string,th string,tr string,tw string,zh string) row format delimited fields terminated by ',' stored as textfile;
INSERT OVERWRITE TABLE game_tag_map SELECT * from gm_gidtagmap;

#统计每个gid对应语言对应tag的play次数
create table game_tag_play_count(gid string,lang string,tag string,time timestamp)row format delimited fields terminated by ',' stored as textfile;
INSERT INTO TABLE game_tag_play_count select /*+ mapjoin(game_tag_map)*/ a.gid,a.language,t.en,a.time from game_tag_map t join game_play_action a on (a.language='en' and a.day>='20140815' and a.gid=substr(t.id,2));
INSERT OVERWRITE LOCAL DIRECTORY '/home/hadoop/tag_play' row format delimited fields terminated by ',' stored as textfile select gid,lang,tag,count(time) from game_tag_play_count group by gid,lang,tag;

#统计大游戏的行为数量
create table ratingmerge(uid string,gid string,rate string,lang string)row format delimited fields terminated by ',' stored as textfile;
LOAD DATA INPATH '/gmrec/rating/merge/part-r-00000' INTO TABLE ratingmerge;
select count(gid) from(select /*+ mapjoin(game_tag_map)*/ r.gid,t.gt from ratingmerge r join game_tag_map t on r.gid=substr(t.id,2))b where gt='w'

#统计推荐带来的play次数
select count(1) from game_play_action where day > '20140822' and rt is not null;

#分别统计最近一个月每个用户玩大小游戏的次数
INSERT OVERWRITE LOCAL DIRECTORY '/home/hadoop/wuzhongju' row format delimited fields terminated by ',' stored as textfile select /*+ mapjoin(g)*/ t.uid,g.gt,count(t.time) from game_play_action t left outer join game_tag_map g on (t.gid=substr(g.id,2)) where t.day >'20140724' group by t.uid,g.gt;
awk -F "," 'BEGIN{total=0}{total+=$3}END{print total}' 000000_0 